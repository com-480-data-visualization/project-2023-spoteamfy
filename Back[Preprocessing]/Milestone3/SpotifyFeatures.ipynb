{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Audio Features from Spotify API\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we retrieve audio features from Spotify API for tracks in the final dataset.\n",
    "We get features we didn't retrieved during the first phase of preprocessing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import base64\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PLAYLIST DATA : Get preview_url, image of the artist, popularity of the song "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define functions to make the get requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First authentication\n",
    "def get_tokens() : \n",
    "    \"\"\"\n",
    "    Get access token for Spotify API\n",
    "    You need to create a Spotify app (https://developer.spotify.com/dashboard) to get the client_id and client_secret.\n",
    "    Then create a file named keys.json with the following structure:\n",
    "    {\n",
    "        \"client_id\": \"your_client_id\",\n",
    "        \"client_secret\": \"your_client_secret\"\n",
    "    }\n",
    "    And store it in the same folder as this notebook.\n",
    "\n",
    "    Returns:\n",
    "        access_token (str): access token for Spotify API\n",
    "    \"\"\"\n",
    "    with open('data/keys.json', 'r') as f:\n",
    "        keys = json.load(f)\n",
    "\n",
    "    client_id = keys['client_id']\n",
    "    client_secret = keys['client_secret']\n",
    "\n",
    "    client_creds = f\"{client_id}:{client_secret}\"\n",
    "    # Encode the concatenated string as base64\n",
    "    client_creds_b64 = base64.b64encode(client_creds.encode())\n",
    "\n",
    "    # Define the headers for the request to the Spotify Accounts service\n",
    "    token_url = 'https://accounts.spotify.com/api/token'\n",
    "    token_data = {\n",
    "        \"grant_type\": \"client_credentials\"\n",
    "    }\n",
    "    token_headers = {\n",
    "        \"Authorization\": f\"Basic {client_creds_b64.decode()}\",\n",
    "    }\n",
    "\n",
    "    # Make the request to the Spotify Accounts service to get an access token\n",
    "    response = requests.post(token_url, data=token_data, headers=token_headers)\n",
    "\n",
    "    # Extract the access token from the response\n",
    "    access_token = response.json()[\"access_token\"]\n",
    "\n",
    "    return access_token\n",
    "\n",
    "def get_audio_features(track_ids, access_token):\n",
    "    \"\"\"\n",
    "    Get audio features from Spotify API for a list of track IDs\n",
    "\n",
    "    Args:\n",
    "        track_ids (list): List of Spotify track IDs\n",
    "        access_token (str): Access token for Spotify API\n",
    "    \n",
    "    Returns:\n",
    "        features_list (list): List of dictionaries containing the audio features for each track\n",
    "    \"\"\"\n",
    "    \n",
    "    # Spotify API endpoint for getting audio features\n",
    "    url = 'https://api.spotify.com/v1/tracks'\n",
    "\n",
    "    # header for the request with authorization token\n",
    "    headers = {\n",
    "        'Authorization': 'Bearer ' + access_token\n",
    "    }\n",
    "\n",
    "    # convert list of track IDs to comma-separated string\n",
    "    track_ids_str = ','.join(track_ids)\n",
    "\n",
    "    # parameters for the request to the Spotify API\n",
    "    params = {\n",
    "        'ids': track_ids_str,\n",
    "        'market': 'US'\n",
    "    }\n",
    "\n",
    "    # make the request to the Spotify API\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    # check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # get the JSON response content\n",
    "        response_json = json.loads(response.content)\n",
    "        # extract the audio features for each track\n",
    "        features_list = []\n",
    "        for track_features in response_json['tracks']:\n",
    "            if len(track_features['album']['images']) == 0:\n",
    "                continue\n",
    "            features = {\n",
    "                'track_id': track_features['id'],\n",
    "                'preview_url': track_features['preview_url'],\n",
    "                'image_url': track_features['album']['images'][0]['url'],\n",
    "                'popularity': track_features['popularity'],\n",
    "            }\n",
    "            features_list.append(features)\n",
    "        return features_list\n",
    "    else:\n",
    "        print('Error:', response.status_code)\n",
    "\n",
    "def retrieve_features_batch(list_ids, access_token, id_batch, last=False, batch_size=50):\n",
    "    \"\"\"\n",
    "    Retrieve audio features for a batch of tracks from the Spotify API\n",
    "\n",
    "    Args:\n",
    "        tracks (pd.DataFrame): Dataframe containing the tracks\n",
    "        access_token (str): Access token for Spotify API\n",
    "        id_batch (int): Batch number\n",
    "        last (bool): True if it is the last batch\n",
    "        batch_size (int): Number of tracks per batch\n",
    "    \n",
    "    Returns:\n",
    "        merged_df (pd.DataFrame): Dataframe containing the tracks and their audio features\n",
    "    \"\"\" \n",
    "    \n",
    "    #Keep a subset of rows from the tracks dataframe\n",
    "    if last:\n",
    "        ids = list_ids[id_batch*batch_size:]\n",
    "    else:\n",
    "        ids = list_ids[id_batch*batch_size:(id_batch+1)*batch_size]\n",
    "\n",
    "    #Get the audio features for the tracks\n",
    "    features_list = get_audio_features(ids, access_token)\n",
    "\n",
    "    #Convert the list of dictionaries to a dataframe\n",
    "    features_df = pd.DataFrame(features_list)\n",
    "\n",
    "    #Merge the audio features with the tracks dataframe on track_id\n",
    "    return features_df\n",
    "            \n",
    "\n",
    "def retrieve_features(list_ids):\n",
    "    \"\"\"\n",
    "    Retrieve audio features for all tracks\n",
    "\n",
    "    Args:\n",
    "        tracks_df : Dataframe of all tracks\n",
    "\n",
    "    Returns:\n",
    "        tracks_final : Dataframe containing the tracks and their audio features\n",
    "    \"\"\"\n",
    "    #Retrieve access_token \n",
    "    access_token = get_tokens()\n",
    "\n",
    "    #Get the number of batches\n",
    "    nb_batches = len(list_ids)//50\n",
    "\n",
    "    #Initialize empty dataframe\n",
    "    tracks_final = None\n",
    "\n",
    "    #Retrieve audio features for each batch\n",
    "    for i in range(nb_batches):\n",
    "        print('Batch {i}/{nb}'.format(i=i, nb=nb_batches+1))\n",
    "        try : \n",
    "            tracks_batch = retrieve_features_batch(list_ids, access_token, i)\n",
    "        except TypeError:\n",
    "            print('Error in batch {i}'.format(i=i))\n",
    "            continue\n",
    "\n",
    "        if i == 0:\n",
    "            tracks_final = tracks_batch\n",
    "        else:\n",
    "            tracks_final = pd.concat([tracks_final, tracks_batch], ignore_index=True)    \n",
    "\n",
    "    return tracks_final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we retrieve the features we are interested in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/260\n",
      "Batch 1/260\n",
      "Batch 2/260\n",
      "Batch 3/260\n",
      "Batch 4/260\n",
      "Batch 5/260\n",
      "Batch 6/260\n",
      "Batch 7/260\n",
      "Batch 8/260\n",
      "Batch 9/260\n",
      "Batch 10/260\n",
      "Batch 11/260\n",
      "Batch 12/260\n",
      "Batch 13/260\n",
      "Batch 14/260\n",
      "Batch 15/260\n",
      "Batch 16/260\n",
      "Batch 17/260\n",
      "Batch 18/260\n",
      "Batch 19/260\n",
      "Batch 20/260\n",
      "Batch 21/260\n",
      "Batch 22/260\n",
      "Batch 23/260\n",
      "Batch 24/260\n",
      "Batch 25/260\n",
      "Batch 26/260\n",
      "Batch 27/260\n",
      "Batch 28/260\n",
      "Batch 29/260\n",
      "Batch 30/260\n",
      "Batch 31/260\n",
      "Batch 32/260\n",
      "Batch 33/260\n",
      "Batch 34/260\n",
      "Batch 35/260\n",
      "Batch 36/260\n",
      "Batch 37/260\n",
      "Batch 38/260\n",
      "Batch 39/260\n",
      "Batch 40/260\n",
      "Batch 41/260\n",
      "Batch 42/260\n",
      "Batch 43/260\n",
      "Batch 44/260\n",
      "Batch 45/260\n",
      "Batch 46/260\n",
      "Batch 47/260\n",
      "Batch 48/260\n",
      "Batch 49/260\n",
      "Batch 50/260\n",
      "Batch 51/260\n",
      "Batch 52/260\n",
      "Batch 53/260\n",
      "Batch 54/260\n",
      "Batch 55/260\n",
      "Batch 56/260\n",
      "Batch 57/260\n",
      "Batch 58/260\n",
      "Batch 59/260\n",
      "Batch 60/260\n",
      "Batch 61/260\n",
      "Batch 62/260\n",
      "Batch 63/260\n",
      "Batch 64/260\n",
      "Batch 65/260\n",
      "Batch 66/260\n",
      "Batch 67/260\n",
      "Batch 68/260\n",
      "Batch 69/260\n",
      "Batch 70/260\n",
      "Batch 71/260\n",
      "Batch 72/260\n",
      "Batch 73/260\n",
      "Batch 74/260\n",
      "Batch 75/260\n",
      "Batch 76/260\n",
      "Batch 77/260\n",
      "Batch 78/260\n",
      "Batch 79/260\n",
      "Batch 80/260\n",
      "Batch 81/260\n",
      "Batch 82/260\n",
      "Batch 83/260\n",
      "Batch 84/260\n",
      "Batch 85/260\n",
      "Batch 86/260\n",
      "Batch 87/260\n",
      "Batch 88/260\n",
      "Batch 89/260\n",
      "Batch 90/260\n",
      "Batch 91/260\n",
      "Batch 92/260\n",
      "Batch 93/260\n",
      "Batch 94/260\n",
      "Batch 95/260\n",
      "Batch 96/260\n",
      "Batch 97/260\n",
      "Batch 98/260\n",
      "Batch 99/260\n",
      "Batch 100/260\n",
      "Batch 101/260\n",
      "Batch 102/260\n",
      "Batch 103/260\n",
      "Batch 104/260\n",
      "Batch 105/260\n",
      "Batch 106/260\n",
      "Batch 107/260\n",
      "Batch 108/260\n",
      "Batch 109/260\n",
      "Batch 110/260\n",
      "Batch 111/260\n",
      "Batch 112/260\n",
      "Batch 113/260\n",
      "Batch 114/260\n",
      "Batch 115/260\n",
      "Batch 116/260\n",
      "Batch 117/260\n",
      "Batch 118/260\n",
      "Batch 119/260\n",
      "Batch 120/260\n",
      "Batch 121/260\n",
      "Batch 122/260\n",
      "Batch 123/260\n",
      "Batch 124/260\n",
      "Batch 125/260\n",
      "Batch 126/260\n",
      "Batch 127/260\n",
      "Batch 128/260\n",
      "Batch 129/260\n",
      "Batch 130/260\n",
      "Batch 131/260\n",
      "Batch 132/260\n",
      "Batch 133/260\n",
      "Batch 134/260\n",
      "Batch 135/260\n",
      "Batch 136/260\n",
      "Batch 137/260\n",
      "Batch 138/260\n",
      "Batch 139/260\n",
      "Batch 140/260\n",
      "Batch 141/260\n",
      "Batch 142/260\n",
      "Batch 143/260\n",
      "Batch 144/260\n",
      "Batch 145/260\n",
      "Batch 146/260\n",
      "Batch 147/260\n",
      "Batch 148/260\n",
      "Batch 149/260\n",
      "Batch 150/260\n",
      "Batch 151/260\n",
      "Batch 152/260\n",
      "Batch 153/260\n",
      "Batch 154/260\n",
      "Batch 155/260\n",
      "Batch 156/260\n",
      "Batch 157/260\n",
      "Batch 158/260\n",
      "Batch 159/260\n",
      "Batch 160/260\n",
      "Batch 161/260\n",
      "Batch 162/260\n",
      "Batch 163/260\n",
      "Batch 164/260\n",
      "Batch 165/260\n",
      "Batch 166/260\n",
      "Batch 167/260\n",
      "Batch 168/260\n",
      "Batch 169/260\n",
      "Batch 170/260\n",
      "Batch 171/260\n",
      "Batch 172/260\n",
      "Batch 173/260\n",
      "Batch 174/260\n",
      "Batch 175/260\n",
      "Batch 176/260\n",
      "Batch 177/260\n",
      "Batch 178/260\n",
      "Batch 179/260\n",
      "Batch 180/260\n",
      "Batch 181/260\n",
      "Batch 182/260\n",
      "Batch 183/260\n",
      "Batch 184/260\n",
      "Batch 185/260\n",
      "Batch 186/260\n",
      "Batch 187/260\n",
      "Batch 188/260\n",
      "Batch 189/260\n",
      "Batch 190/260\n",
      "Batch 191/260\n",
      "Batch 192/260\n",
      "Batch 193/260\n",
      "Batch 194/260\n",
      "Batch 195/260\n",
      "Batch 196/260\n",
      "Batch 197/260\n",
      "Batch 198/260\n",
      "Batch 199/260\n",
      "Batch 200/260\n",
      "Batch 201/260\n",
      "Batch 202/260\n",
      "Batch 203/260\n",
      "Batch 204/260\n",
      "Batch 205/260\n",
      "Batch 206/260\n",
      "Batch 207/260\n",
      "Batch 208/260\n",
      "Batch 209/260\n",
      "Batch 210/260\n",
      "Batch 211/260\n",
      "Batch 212/260\n",
      "Batch 213/260\n",
      "Batch 214/260\n",
      "Batch 215/260\n",
      "Batch 216/260\n",
      "Batch 217/260\n",
      "Batch 218/260\n",
      "Batch 219/260\n",
      "Batch 220/260\n",
      "Batch 221/260\n",
      "Batch 222/260\n",
      "Batch 223/260\n",
      "Batch 224/260\n",
      "Batch 225/260\n",
      "Batch 226/260\n",
      "Batch 227/260\n",
      "Batch 228/260\n",
      "Batch 229/260\n",
      "Batch 230/260\n",
      "Batch 231/260\n",
      "Batch 232/260\n",
      "Batch 233/260\n",
      "Batch 234/260\n",
      "Batch 235/260\n",
      "Batch 236/260\n",
      "Batch 237/260\n",
      "Batch 238/260\n",
      "Batch 239/260\n",
      "Batch 240/260\n",
      "Batch 241/260\n",
      "Batch 242/260\n",
      "Batch 243/260\n",
      "Batch 244/260\n",
      "Batch 245/260\n",
      "Batch 246/260\n",
      "Batch 247/260\n",
      "Batch 248/260\n",
      "Batch 249/260\n",
      "Batch 250/260\n",
      "Batch 251/260\n",
      "Batch 252/260\n",
      "Batch 253/260\n",
      "Batch 254/260\n",
      "Batch 255/260\n",
      "Batch 256/260\n",
      "Batch 257/260\n",
      "Batch 258/260\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/tracks_final.csv')\n",
    "access_token = get_tokens()\n",
    "tracks_ids = df['track_id'].tolist()\n",
    "\n",
    "df_spotify = retrieve_features(tracks_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5801\n",
      "522\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotions</th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "      <th>tags</th>\n",
       "      <th>arousal</th>\n",
       "      <th>dominance</th>\n",
       "      <th>track_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>...</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>preview_url</th>\n",
       "      <th>image_url</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4710</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>Waving My Arms In The Air [Take 1]</td>\n",
       "      <td>Syd Barrett</td>\n",
       "      <td>['ominous' 'fractured' 'insular' 'wry' 'eccent...</td>\n",
       "      <td>3.620607</td>\n",
       "      <td>4.231495</td>\n",
       "      <td>0pMOAZz9GxlXi2fXkRr0nN</td>\n",
       "      <td>psychedelic rock</td>\n",
       "      <td>0.793000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>-17.179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>105.726</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4620</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/d94c05e855b75f7b...</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273e16120...</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14603</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>Uni Iso</td>\n",
       "      <td>Alva Noto</td>\n",
       "      <td>['intimate' 'nervous']</td>\n",
       "      <td>5.850000</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>158gPbiLX3MUEptQOJgQES</td>\n",
       "      <td>glitch</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0513</td>\n",
       "      <td>-17.213</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>127.642</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/8b9cdbe7caaba45b...</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273f6b517...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2940</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>Nobody Loves You Like I Do</td>\n",
       "      <td>MakTub</td>\n",
       "      <td>['harsh' 'urgent' 'yearning']</td>\n",
       "      <td>3.976000</td>\n",
       "      <td>4.889000</td>\n",
       "      <td>6C7NKesRR4mN3Dr4goQHlh</td>\n",
       "      <td>singer-songwriter</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>-8.650</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>111.080</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/f038a8eb1f7c886c...</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273b14263...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4067</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>Harem Scarem</td>\n",
       "      <td>Focus</td>\n",
       "      <td>['manic' 'eerie' 'urgent' 'campy' 'passionate']</td>\n",
       "      <td>4.432000</td>\n",
       "      <td>3.902000</td>\n",
       "      <td>0QhfAl5OwRfnBfqLlV3b6N</td>\n",
       "      <td>progressive rock</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>-9.591</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>88.484</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6940</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/a9d1a681a79af067...</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b2733aaa4d...</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5160</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>Song Slowly Song</td>\n",
       "      <td>Tim Buckley</td>\n",
       "      <td>['visceral' 'eerie' 'dramatic' 'mysterious' 'p...</td>\n",
       "      <td>4.466847</td>\n",
       "      <td>4.379754</td>\n",
       "      <td>5fbNnnlxmbzCHUwBjNHrys</td>\n",
       "      <td>singer-songwriter</td>\n",
       "      <td>0.909000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0985</td>\n",
       "      <td>-24.306</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0367</td>\n",
       "      <td>100.523</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1560</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/90e97bb4681e8e7f...</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273e55d5b...</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12946</th>\n",
       "      <td>11471</td>\n",
       "      <td>love</td>\n",
       "      <td>Everyday (#36)</td>\n",
       "      <td>Dave Matthews Band</td>\n",
       "      <td>['nocturnal' 'ambitious' 'carefree' 'freewheel...</td>\n",
       "      <td>4.017569</td>\n",
       "      <td>6.008692</td>\n",
       "      <td>5Q2ZrpifaZkCuk6XIPH1cb</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>0.487000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>-7.505</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>92.463</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4140</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/1e1954f2c20ee681...</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273ebfdb8...</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12947</th>\n",
       "      <td>11520</td>\n",
       "      <td>love</td>\n",
       "      <td>old dirt hill</td>\n",
       "      <td>Dave Matthews Band</td>\n",
       "      <td>['nocturnal' 'ambitious' 'carefree' 'freewheel...</td>\n",
       "      <td>3.843571</td>\n",
       "      <td>5.893571</td>\n",
       "      <td>1GCaJJ1JoTTlD6SvNTVlqo</td>\n",
       "      <td>rock</td>\n",
       "      <td>0.297000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2260</td>\n",
       "      <td>-6.271</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>113.533</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/d106766a8fba79ff...</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273c7ad81...</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12948</th>\n",
       "      <td>11540</td>\n",
       "      <td>love</td>\n",
       "      <td>Everybody Wake Up</td>\n",
       "      <td>Dave Matthews Band</td>\n",
       "      <td>['nocturnal' 'ambitious' 'carefree' 'freewheel...</td>\n",
       "      <td>3.843571</td>\n",
       "      <td>5.893571</td>\n",
       "      <td>3YQh1MeWtF2doriJTZTzO6</td>\n",
       "      <td>rock</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>-4.162</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0399</td>\n",
       "      <td>110.993</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4550</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/3b60b984e24e2bc0...</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273c7ad81...</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12949</th>\n",
       "      <td>11544</td>\n",
       "      <td>love</td>\n",
       "      <td>Stand Up</td>\n",
       "      <td>Dave Matthews Band</td>\n",
       "      <td>['nocturnal' 'ambitious' 'carefree' 'freewheel...</td>\n",
       "      <td>3.843571</td>\n",
       "      <td>5.893571</td>\n",
       "      <td>0UxvDe61JZFfDopF1hM6Hp</td>\n",
       "      <td>rock</td>\n",
       "      <td>0.073200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3260</td>\n",
       "      <td>-5.958</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>123.898</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7380</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/06a74e81897f724e...</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273c7ad81...</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12950</th>\n",
       "      <td>11568</td>\n",
       "      <td>love</td>\n",
       "      <td>Pantala Naga Pampa (Rapunzel)</td>\n",
       "      <td>Dave Matthews Band</td>\n",
       "      <td>['nocturnal' 'ambitious' 'carefree' 'freewheel...</td>\n",
       "      <td>3.804000</td>\n",
       "      <td>5.870667</td>\n",
       "      <td>0fJKMX81Qqhxrv2fdP8B8K</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8460</td>\n",
       "      <td>-4.856</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>99.433</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4470</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/3b0273f372c8161e...</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273ac9605...</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6811 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id      emotions                               track  \\\n",
       "0       4710  anticipation  Waving My Arms In The Air [Take 1]   \n",
       "1      14603  anticipation                             Uni Iso   \n",
       "3       2940  anticipation          Nobody Loves You Like I Do   \n",
       "4       4067  anticipation                        Harem Scarem   \n",
       "5       5160  anticipation                    Song Slowly Song   \n",
       "...      ...           ...                                 ...   \n",
       "12946  11471          love                      Everyday (#36)   \n",
       "12947  11520          love                       old dirt hill   \n",
       "12948  11540          love                   Everybody Wake Up   \n",
       "12949  11544          love                            Stand Up   \n",
       "12950  11568          love       Pantala Naga Pampa (Rapunzel)   \n",
       "\n",
       "                   artist                                               tags  \\\n",
       "0             Syd Barrett  ['ominous' 'fractured' 'insular' 'wry' 'eccent...   \n",
       "1               Alva Noto                             ['intimate' 'nervous']   \n",
       "3                  MakTub                      ['harsh' 'urgent' 'yearning']   \n",
       "4                   Focus    ['manic' 'eerie' 'urgent' 'campy' 'passionate']   \n",
       "5             Tim Buckley  ['visceral' 'eerie' 'dramatic' 'mysterious' 'p...   \n",
       "...                   ...                                                ...   \n",
       "12946  Dave Matthews Band  ['nocturnal' 'ambitious' 'carefree' 'freewheel...   \n",
       "12947  Dave Matthews Band  ['nocturnal' 'ambitious' 'carefree' 'freewheel...   \n",
       "12948  Dave Matthews Band  ['nocturnal' 'ambitious' 'carefree' 'freewheel...   \n",
       "12949  Dave Matthews Band  ['nocturnal' 'ambitious' 'carefree' 'freewheel...   \n",
       "12950  Dave Matthews Band  ['nocturnal' 'ambitious' 'carefree' 'freewheel...   \n",
       "\n",
       "        arousal  dominance                track_id              genre  \\\n",
       "0      3.620607   4.231495  0pMOAZz9GxlXi2fXkRr0nN   psychedelic rock   \n",
       "1      5.850000   5.533333  158gPbiLX3MUEptQOJgQES             glitch   \n",
       "3      3.976000   4.889000  6C7NKesRR4mN3Dr4goQHlh  singer-songwriter   \n",
       "4      4.432000   3.902000  0QhfAl5OwRfnBfqLlV3b6N   progressive rock   \n",
       "5      4.466847   4.379754  5fbNnnlxmbzCHUwBjNHrys  singer-songwriter   \n",
       "...         ...        ...                     ...                ...   \n",
       "12946  4.017569   6.008692  5Q2ZrpifaZkCuk6XIPH1cb           acoustic   \n",
       "12947  3.843571   5.893571  1GCaJJ1JoTTlD6SvNTVlqo               rock   \n",
       "12948  3.843571   5.893571  3YQh1MeWtF2doriJTZTzO6               rock   \n",
       "12949  3.843571   5.893571  0UxvDe61JZFfDopF1hM6Hp               rock   \n",
       "12950  3.804000   5.870667  0fJKMX81Qqhxrv2fdP8B8K           acoustic   \n",
       "\n",
       "       acousticness  ...  liveness  loudness  mode  speechiness    tempo  \\\n",
       "0          0.793000  ...    0.1490   -17.179     1       0.0430  105.726   \n",
       "1          0.000015  ...    0.0513   -17.213     1       0.0528  127.642   \n",
       "3          0.030000  ...    0.1520    -8.650     1       0.0279  111.080   \n",
       "4          0.022800  ...    0.1140    -9.591     1       0.0342   88.484   \n",
       "5          0.909000  ...    0.0985   -24.306     0       0.0367  100.523   \n",
       "...             ...  ...       ...       ...   ...          ...      ...   \n",
       "12946      0.487000  ...    0.9730    -7.505     1       0.0359   92.463   \n",
       "12947      0.297000  ...    0.2260    -6.271     1       0.0312  113.533   \n",
       "12948      0.031700  ...    0.1640    -4.162     1       0.0399  110.993   \n",
       "12949      0.073200  ...    0.3260    -5.958     1       0.1280  123.898   \n",
       "12950      0.228000  ...    0.8460    -4.856     1       0.1290   99.433   \n",
       "\n",
       "       time_signature  valence  \\\n",
       "0                   4   0.4620   \n",
       "1                   4   0.0567   \n",
       "3                   4   0.5050   \n",
       "4                   4   0.6940   \n",
       "5                   4   0.1560   \n",
       "...               ...      ...   \n",
       "12946               4   0.4140   \n",
       "12947               4   0.8710   \n",
       "12948               4   0.4550   \n",
       "12949               4   0.7380   \n",
       "12950               4   0.4470   \n",
       "\n",
       "                                             preview_url  \\\n",
       "0      https://p.scdn.co/mp3-preview/d94c05e855b75f7b...   \n",
       "1      https://p.scdn.co/mp3-preview/8b9cdbe7caaba45b...   \n",
       "3      https://p.scdn.co/mp3-preview/f038a8eb1f7c886c...   \n",
       "4      https://p.scdn.co/mp3-preview/a9d1a681a79af067...   \n",
       "5      https://p.scdn.co/mp3-preview/90e97bb4681e8e7f...   \n",
       "...                                                  ...   \n",
       "12946  https://p.scdn.co/mp3-preview/1e1954f2c20ee681...   \n",
       "12947  https://p.scdn.co/mp3-preview/d106766a8fba79ff...   \n",
       "12948  https://p.scdn.co/mp3-preview/3b60b984e24e2bc0...   \n",
       "12949  https://p.scdn.co/mp3-preview/06a74e81897f724e...   \n",
       "12950  https://p.scdn.co/mp3-preview/3b0273f372c8161e...   \n",
       "\n",
       "                                               image_url  popularity  \n",
       "0      https://i.scdn.co/image/ab67616d0000b273e16120...        13.0  \n",
       "1      https://i.scdn.co/image/ab67616d0000b273f6b517...         4.0  \n",
       "3      https://i.scdn.co/image/ab67616d0000b273b14263...         2.0  \n",
       "4      https://i.scdn.co/image/ab67616d0000b2733aaa4d...        26.0  \n",
       "5      https://i.scdn.co/image/ab67616d0000b273e55d5b...        14.0  \n",
       "...                                                  ...         ...  \n",
       "12946  https://i.scdn.co/image/ab67616d0000b273ebfdb8...        28.0  \n",
       "12947  https://i.scdn.co/image/ab67616d0000b273c7ad81...        33.0  \n",
       "12948  https://i.scdn.co/image/ab67616d0000b273c7ad81...        27.0  \n",
       "12949  https://i.scdn.co/image/ab67616d0000b273c7ad81...        27.0  \n",
       "12950  https://i.scdn.co/image/ab67616d0000b273ac9605...        23.0  \n",
       "\n",
       "[6811 rows x 24 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge to the initial datframe\n",
    "df_final = pd.merge(df, df_spotify, on='track_id', how='left')\n",
    "\n",
    "#Check how many nan values there are on column preview_url\n",
    "print(df_final['preview_url'].isna().sum())\n",
    "print(df_final['genre'].isna().sum())\n",
    "\n",
    "#Drop rows with nan values on column preview_url\n",
    "df_final = df_final.dropna(subset=['preview_url'])\n",
    "df_final = df_final.dropna(subset=['genre'])\n",
    "\n",
    "df_final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retrieve the features we are interested for the playlist on the website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anticipation 33\n",
      "anger 341\n",
      "disgust 74\n",
      "contempt 414\n",
      "sadness 1735\n",
      "remorse 337\n",
      "surprise 3\n",
      "fear 423\n",
      "awe 5\n",
      "trust 394\n",
      "submission 1\n",
      "joy 1948\n",
      "optimism 356\n",
      "love 747\n"
     ]
    }
   ],
   "source": [
    "#for each emotion, retrieve subset of tracks\n",
    "emotions = df_final['emotions'].unique()\n",
    "emotion2tracks = {}\n",
    "\n",
    "for emotion in emotions:\n",
    "    df_emotion = df_final[df_final['emotions'] == emotion][['track_id', 'track', 'artist', 'preview_url', 'image_url', 'popularity', 'genre']] \n",
    "    df_emotion = df_emotion.sort_values(by='popularity', ascending=False)\n",
    "    \n",
    "    #Store as a list of dictionaries to then convert to JSON\n",
    "    tracks_list = []\n",
    "    for index, row in df_emotion.iterrows():\n",
    "        track = {\n",
    "            'track': row['track'],\n",
    "            'artist': row['artist'],\n",
    "            'preview_url': row['preview_url'],\n",
    "            'image_url': row['image_url'],\n",
    "            'play' : 0,\n",
    "            'genre' : row['genre']\n",
    "        }\n",
    "        tracks_list.append(track)\n",
    "    emotion2tracks[emotion] = tracks_list\n",
    "\n",
    "#Save as JSON file\n",
    "with open('data/data_playlists.json', 'w') as fp:\n",
    "    json.dump(emotion2tracks, fp)\n",
    "\n",
    "#Print number of tracks per emotion\n",
    "for key, value in emotion2tracks.items():\n",
    "    print(key, len(value))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ARTISTS DATA : Retrieve pictures of top 10 artists per emotion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get pictures of artists\n",
    "def get_artist_features(track_id, access_token):\n",
    "    \"\"\"\n",
    "    Get audio features from Spotify API for a list of track IDs\n",
    "\n",
    "    Args:\n",
    "        track_ids (list): List of Spotify track IDs\n",
    "        access_token (str): Access token for Spotify API\n",
    "    \n",
    "    Returns:\n",
    "        features_list (list): List of dictionaries containing the audio features for each track\n",
    "    \"\"\"\n",
    "    \n",
    "    # Spotify API endpoint for getting audio features\n",
    "    url = 'https://api.spotify.com/v1/tracks/'+track_id\n",
    "\n",
    "    # header for the request with authorization token\n",
    "    headers = {\n",
    "        'Authorization': 'Bearer ' + access_token\n",
    "    }\n",
    "\n",
    "    # make the request to the Spotify API\n",
    "    response = requests.get(url, headers=headers)\n",
    "    # check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # get the JSON response content\n",
    "        response_json = json.loads(response.content)\n",
    "        # extract uri of the artist\n",
    "        artist_id = response_json['artists'][0]['id']\n",
    "        url_image, width, height = get_artist_image(artist_id, access_token)\n",
    "\n",
    "        return url_image, width, height\n",
    "\n",
    "    else:\n",
    "        print('Error:', response.status_code)\n",
    "\n",
    "\n",
    "#Get pictures of artists\n",
    "def get_artist_image(artist_id, access_token):\n",
    "    \"\"\"\n",
    "    Get audio features from Spotify API for a list of track IDs\n",
    "\n",
    "    Args:\n",
    "        track_ids (list): List of Spotify track IDs\n",
    "        access_token (str): Access token for Spotify API\n",
    "    \n",
    "    Returns:\n",
    "        features_list (list): List of dictionaries containing the audio features for each track\n",
    "    \"\"\"\n",
    "    \n",
    "    # Spotify API endpoint for getting audio features\n",
    "    url = 'https://api.spotify.com/v1/artists/'+artist_id\n",
    "\n",
    "    # header for the request with authorization token\n",
    "    headers = {\n",
    "        'Authorization': 'Bearer ' + access_token\n",
    "    }\n",
    "\n",
    "    # make the request to the Spotify API\n",
    "    response = requests.get(url, headers=headers)\n",
    "    # check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # get the JSON response content\n",
    "        response_json = json.loads(response.content)\n",
    "        # extract uri of the artist\n",
    "\n",
    "        #If there is no image, return None\n",
    "        if len(response_json['images']) == 0:\n",
    "            print(artist_id)\n",
    "\n",
    "            return None, None, None\n",
    "        \n",
    "        artist_url = response_json['images'][0]['url']\n",
    "        width = response_json['images'][0]['width']\n",
    "        height = response_json['images'][0]['height']\n",
    "\n",
    "        return artist_url, width, height\n",
    "\n",
    "    else:\n",
    "        print(artist_id)\n",
    "        print('Error:', response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the JSON file\n",
    "with open('data/top_artists.json') as json_file:\n",
    "    top_artists = json.load(json_file)\n",
    "\n",
    "#Retrieve access_token\n",
    "access_token = get_tokens()\n",
    "\n",
    "#Get the picture of each artist\n",
    "for key, value in top_artists.items():\n",
    "    for val in value : \n",
    "        artist_url, width, height = get_artist_features(val['track_id'], access_token)\n",
    "        val['image_url'] = artist_url\n",
    "        val['width'] = width\n",
    "        val['height'] = height\n",
    "\n",
    "#Write the JSON file\n",
    "with open('data/top_artists.json', 'w') as fp:\n",
    "    json.dump(top_artists, fp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Retrieve mean of audio features for each emotion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/tracks_final.csv')\n",
    "\n",
    "#Keep only the columns we need\n",
    "to_keep = ['emotions', 'danceability', 'arousal', 'dominance', 'energy', 'loudness',\n",
    "             'acousticness', 'instrumentalness', 'valence']\n",
    "df = df[to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotions</th>\n",
       "      <th>danceability</th>\n",
       "      <th>arousal</th>\n",
       "      <th>dominance</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anticipation</td>\n",
       "      <td>84</td>\n",
       "      <td>51</td>\n",
       "      <td>55</td>\n",
       "      <td>12</td>\n",
       "      <td>57</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anticipation</td>\n",
       "      <td>37</td>\n",
       "      <td>86</td>\n",
       "      <td>75</td>\n",
       "      <td>34</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anticipation</td>\n",
       "      <td>31</td>\n",
       "      <td>66</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>78</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anticipation</td>\n",
       "      <td>67</td>\n",
       "      <td>57</td>\n",
       "      <td>65</td>\n",
       "      <td>43</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anticipation</td>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12985</th>\n",
       "      <td>love</td>\n",
       "      <td>59</td>\n",
       "      <td>57</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>79</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12986</th>\n",
       "      <td>love</td>\n",
       "      <td>31</td>\n",
       "      <td>61</td>\n",
       "      <td>78</td>\n",
       "      <td>18</td>\n",
       "      <td>58</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12987</th>\n",
       "      <td>love</td>\n",
       "      <td>76</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>62</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12988</th>\n",
       "      <td>love</td>\n",
       "      <td>43</td>\n",
       "      <td>67</td>\n",
       "      <td>88</td>\n",
       "      <td>87</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12989</th>\n",
       "      <td>love</td>\n",
       "      <td>55</td>\n",
       "      <td>58</td>\n",
       "      <td>80</td>\n",
       "      <td>61</td>\n",
       "      <td>77</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12990 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           emotions  danceability  arousal  dominance  energy  loudness  \\\n",
       "0      anticipation            84       51         55      12        57   \n",
       "1      anticipation            37       86         75      34        57   \n",
       "2      anticipation            31       66         60      58        78   \n",
       "3      anticipation            67       57         65      43        74   \n",
       "4      anticipation            48       64         50      80        72   \n",
       "...             ...           ...      ...        ...     ...       ...   \n",
       "12985          love            59       57         80      70        79   \n",
       "12986          love            31       61         78      18        58   \n",
       "12987          love            76       60         80       6        62   \n",
       "12988          love            43       67         88      87        83   \n",
       "12989          love            55       58         80      61        77   \n",
       "\n",
       "       acousticness  instrumentalness  valence  \n",
       "0                80                 0       47  \n",
       "1                 0                91        6  \n",
       "2                 9                 0        9  \n",
       "3                 3                 0       51  \n",
       "4                 2                87       70  \n",
       "...             ...               ...      ...  \n",
       "12985            10                 0       15  \n",
       "12986            94                 0       16  \n",
       "12987            99                 0        7  \n",
       "12988             0                 0       27  \n",
       "12989             5                 0       24  \n",
       "\n",
       "[12990 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale all audio features so that all values are between 0 and 100\n",
    "for i in to_keep[1:]:\n",
    "    df[i] = round((df[i] - df[i].min()) / (df[i].max() - df[i].min()) * 100).astype(int)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anticipation\n",
      "anger\n",
      "disgust\n",
      "contempt\n",
      "sadness\n",
      "remorse\n",
      "surprise\n",
      "fear\n",
      "awe\n",
      "trust\n",
      "submission\n",
      "joy\n",
      "optimism\n",
      "love\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\affol\\AppData\\Local\\Temp/ipykernel_25680/1589508833.py:9: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df_emotion_mean = df_emotion.mean()\n"
     ]
    }
   ],
   "source": [
    "#Retrieve emotions\n",
    "emotions = df['emotions'].unique()\n",
    "dict_features = {}\n",
    "\n",
    "#For each emotion, compute the mean of each audio feature\n",
    "for emotion in emotions : \n",
    "    print(emotion)\n",
    "    df_emotion = df[df['emotions'] == emotion]\n",
    "    df_emotion_mean = df_emotion.mean()\n",
    "    df_emotion_mean = df_emotion_mean.round(decimals=1) #Round to 1 decimal\n",
    "    df_emotion_mean = df_emotion_mean.sort_values(ascending=False).to_dict() #Sort by descending order\n",
    "    dict_features[emotion] = df_emotion_mean\n",
    "\n",
    "#Write the JSON file\n",
    "with open('data/features.json', 'w') as fp:\n",
    "    json.dump(dict_features, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaexam2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
